\label{sec-measurement-setup}

Tutkielmaa varten laadittiin synteettinen
benchmarking-mittausohjelmisto (/microbenchmarking suite/)
/NativeBenchmark/. Ohjelmiston avulla Android-laitteessa voidaan
suorittaa kokoelma minimaalisia aliohjelmia (jatkossa
alkeisoperaatioita), jotka yhdessä harjoittavat kattavasti
JNI-rajapinnan eri kutsuja.

Kun alkeisoperaatioita suoritetaan laitteessa, samojen operaatioiden
suoritusta mitataan kahdella toisiaan täydentävällä menetelmällä eri
mittausajojen aikana: ensin yksittäisen aliohjelman suorituksen
kokonaisvasteaika mitataan Javan \path{System.nanoTime()}-metodilla, ja
seuraavassa ajossa samoille aliohjelmille luodaan
näytteenottomenetelmällä kutsuprofiilit Linuxin \path{perf}-työkalun
avulla.

* Mittausten tavoitteet

# [[sec-5][5, s.]]
# [[file:performance.org::*Mittauskohteen%20edustavuus%20ja%20tulosten%20yleistett%C3%A4vyys][Mittauskohteen edustavuus ja tulosten yleistettävyys]]
# todo sisäinen viittaus tohon alle: miten ?

Yksittäisen funktiokutsun mitattu vasteaika ei kerro mitään
yleispätevää kyseisestä funktiosta
(ks. luku \ref{performance:representativeness-generalization},
s.\pageref{performance:representativeness-generalization}). Siksi samaa
funktiota kutsutaan varioiden kaikkia mahdollisia asioita, joita
funktiokutsussa voi varioida: käytännössä kutsuparametrien määrää ja
niiden tyyppiä. Lisäksi jos kyseessä on merkkijonoja, taulukoita tai
muita vaihtelevankokoisia syötteitä käsittelevä funktio, varioidaan
käsiteltävän syötteen kokoa.

Esimerksi JNI-funktio \path{CallVoidMethod} vastaanottaa vaihtelevan määrän
kutsuparametreja. Mittausajoissa sitä kutsutaan eri määrillä eri
tyyppisiä parametreja, jolloin saadaan selville muun muassa, käyttäytyykö
funktio eri tavalla käsitellessään primitiivityyppisiä ja
viitetyyppisiä parametreja.

Tämän ansiosta mittauksista piirtyy hieman kokonaisvaltaisempi kuva
siitä, mitkä mittauksessa varioitavat muuttujat ovat oleellisia
funktion suorituskyvyn kannalta.

Toinen tapa lisätä tulosten hyödynnettävyyttä on seuraava periaate:
jos jollekin JNI-kutsulle on keksitty analoginen kutsu tai operaatio
JNI-rajapinnan ulkopuolelta -- operaatio, jonka voi toteuttaa
puhtaasti C- tai Java-kielisessä ohjelmassa -- lisätään mittauksiin
tällaiset benchmarkit. Siten esimerkiksi JNI-rajapinnan
\path{CallVoidMethod}- perusfunktiokutsun kaikille variaatioille on
laadittu vertailukohdaksi benchmarkit, joissa C-ohjelma
kutsuu aivan tavallista ~void~-paluuarvollista funktiota,
ja Java-ohjelma vastaavasti kutsuu ~void~-paluuarvollista metodia.

Kolmas tapa saada syvempiä tuloksia JNI-rajapinnan käyttäytymisestä on
mitata samoista benchmarkeista myös kutsuprofiilit. Kun
vasteaikamittauksista on löytynyt mielenkiintoisia riippuvuuksia
varioitavien mittausmuuttujien ja vasteaikojen väliltä, nähdään
saman benchmarkin kutsuprofiileista usein selvästi, mikä
JNI-toteutuksen osa aiheuttaa esimerkiksi lineaarisesti lisääntyvän
vasteajan, kun vaikkapa viitearvoisten kutsuparametrien määrää
lisätään.

* Toteutuksen haasteet ja reunaehdot

Erilaisten kutsuvariaatioiden kokonaismäärä on suuri, eikä
variaatioita voi yleensä toteuttaa ajonaikaisina muutoksina ohjelman
syötteissä: esimerkiksi metodiparametrien määrät on Java-ohjelmassa
lukittava käännösaikana. Variaatioista on vieläpä parhaimmillaan
luotava 4 eri versiota:

# footnote http://docs.oracle.com/javase/1.5.0/docs/guide/language/varargs.html
# javan varargs on vain syntaktista sokeria arraylle

1. puhdas C-kielinen versio,
2. puhdas Java-kielinen versio,
3. Java-ohjelma, joka kutsuu natiivimetodia, sekä
4. C-ohjelma, joka kutsuu Java-metodia.

Variaatioiden hallitsemiseksi on hyödynnetään yksinkertaista
staattista metaohjelmointia: benchmarkeja ei ohjelmoida käsin, vaan
niiden lähdekoodi generoidaan tietorakenteista, joihin on kuvattu
halutut tyyppivariaatiot.

# Esimerkki ?  / bit of source

Koska Java-kieli ei suoraan tue staattisen metaohjelmoinnin mahdollisuutta,
eikä C++-kielen templateja voisi hyödyntää kuin natiiviversioiden
ohjelmointiin, päätettiin lähdekoodin generointi tehdä täysin
erillisellä Python-kielisellä ohjelmalla.

Seuraavassa hahmotellaan tästä perusratkaisusta syntynyttä
arkkitehtuuria.

* TODO Ohjelmiston kokonaisarkkitehtuuri

Ohjelmisto koostuu kolmesta komponentista, joista käännöstyökalut ja
analyysityökalut ajetaan kehitysympäristössä työpöytä-Linux-järjestelmässä ja
mittaustyökalut Android-laitteessa.

#+NAME: fig:architecture
#+INCLUDE: "../../src/figures/architecture.puml" src plantuml :results file :file /tmp/architecture.png :exports results
#+CAPTION: Arkkitehtuurin yleiskuvaus
#+LABEL: fig:architecture
#+RESULTS: fig:architecture

Ohjelmiston pääkomponentit näkyvät kuvassa \ref{fig:architecture}, ja
ne käsitellään seuraavassa tarkemmin.

** TODO lisää tekstiä tähän

* Android-sovellus NativeBenchmark

#+NAME: fig:nativebenchmark_architecture
#+INCLUDE: "../../src/figures/architecture-nativebenchmark.puml" src plantuml :results file :file /tmp/architecture-nativebenchmark.png :exports results
#+CAPTION: NativeBenchmark
#+LABEL: fig:nativebenchmark_architecture
#+RESULTS: fig:nativebenchmark_architecture

Android-sovellus \path{NativeBenchmark} sisältää kaiken Android-laitteessa
suoritettavan ohjelmakoodin: sekä Java-kieliset että natiivikirjastoon
kuuluvat benchmarkit, mutta myös niiden ympärille vaadittavan
logiikan, joka suorittaa halutut benchmarkit valituilla
mittaustyökaluilla.

NativeBenchmark huolehtii mittausajoja koskevien asetustiedostojen
lukemisesta ja tulostaa kaikki mittaustulokset ja niihin liittyvän
metadatan tiedostoihin. Sovelluksessa on yksinkertainen graafinen
Android-käyttöliittymä, mutta sovellusta voi ohjata myös laitteen
ulkopuolelta tekstikomentojen avulla TCP-yhteyden välityksellä.

Sovelluksen keskeisimmät osat ovat
- ~benchmark~ -paketin sisältämät generoidut benchmarkit,
- ~libnativebenchmark~ -natiivikirjasto, joka sisältää generoitujen benchmarkien natiiviosat,
- ~BenchmarkRunner~ -luokka,
- ~MeasuringTool~ -luokan kaksi aliluokkaa
  \path{JavaSystemNanoResponseTimeRecorder} sekä \path{LinuxPerfRecordTool}.

Benchmarkit ovat pohjimmiltaan vain monta kertaa toistettavia
silmukoita (/lähtösilmukoita/), joiden sisällä kutsutaan tutkinnan kohteena olevaa
JNI-palvelua tai sen verrokkia. Jokainen benchmark on ympäröity
samanrakenteisella Java-kielisellä \path{BenchMark}-luokan aliluokalla
silloinkin, kun kyseessä on sellainen verrokkioperaatio, joka
suoritetaan puhtaasti \path{libnativebenchmark}-natiivikirjaston
sisällä. Tällaisessakin tapauksessa mittauksen kuitenkin aina
käynnistää \path{BenchmarkRunner} -Java-olio.

Ajettavat benchmarkit jakautuvat kahteen joukkoon. Ensimmäinen koostuu
yksinkertaisista funktiokutsusta JNI-rajapinnan kautta: C-koodissa
kutsuista \verb|Call|\tau\verb|Method| -funktioihin ja Java-koodissa
kutsuista ~native~ -määreellä merkittyihin ~nativemethod~ -nimisiin
metodeihin. Toinen joukko testaa JNI-rajapinnan muita palveluita.

Seuraavaksi havainnollistetaan ensimmäisen joukon kaikkia neljää
permutaatiota, jotka saadaan lähtösilmukoiden ja kutsukohteiden
toteutuskielistä: (Java \rightarrow C), (Java \rightarrow Java), (C
\rightarrow Java) sekä (C \rightarrow C). Aluksi käsitellään kutsu
Javasta C:hen.

#+NAME: fig:sequence_java_to_c
#+INCLUDE: ../../src/figures/sequence-java-to-c.puml" src plantuml :results file :file /tmp/sequence-java-to-c.png :exports results
#+ATTR_LATEX: :width {0.8\linewidth} :placement [h]
#+CAPTION: Javasta kutsutaan natiivikomponenttia
#+LABEL: fig:sequence_java_to_c
#+RESULTS: fig:sequence_java_to_c

Kuvan \ref{fig:sequence_java_to_c} sekvenssikaaviossa lähtösilmukka on
Java-komponentissa (metodissa
\path{J2CBenchmark00026.runInternal}). Lähtösilmukkaa toistettaessa
ylitetään hyvin monta kertaa JNI-rajapinta ja kutsutaan sen kautta
~libnativebenchmark~-natiivikirjastossa olevaa metodia, jonka sisältö
on tyhjä. Näin ollen mittauksen kohde on käytännössä juuri JNI-kutsu.


#+NAME: fig:sequence_java_to_java
#+INCLUDE: ../../src/figures/sequence-java-to-java.puml" src plantuml :results file :file /tmp/sequence-java-to-java.png :exports results
#+ATTR_LATEX: :width {0.4\linewidth} :placement [b]
#+CAPTION: Javasta kutsutaan Java-metodia
#+LABEL: fig:sequence_java_to_java
#+RESULTS: fig:sequence_java_to_java

Kuvassa \ref{fig:sequence_java_to_java} nähdään yksinkertaisempi
asetelma, jossa Java-ohjelma kutsuu sisäisesti tavallista Java-metodia
ilman JNI-rajapintaa.  \path{JavaCounterparts}-luokka sisältää kaikki
tyhjät metodit joita voidaan kutsua Java- tai C-lähtösilmukasta. Samaa
luokkaa hyödynnetään myös seuraavassa tapauksessa, jossa
C-lähtösilmukka kutsuu Java-tynkämetodia.

#+NAME: fig:sequence_c_to_java
#+INCLUDE: ../../src/figures/sequence-c-to-java.puml" src plantuml :results file :file /tmp/sequence-c-to-java.png :exports results
#+CAPTION: Natiivikomponentista kutsutaan Java-metodia
#+LABEL: fig:sequence_c_to_java
#+RESULTS: fig:sequence_c_to_java

Kuvasta \ref{fig:sequence_c_to_java} nähdään, että JNI-rajapinta
ylitetään kahdessa kohtaa. Molemmat kuvassa näkyvät
Dalvik-virtuaalikoneet edustavat samaa instanssia, joka on selkeyden
vuoksi piirretty kaksi kertaa. Ensinnäkin, koska tällä kertaa
lähtösilmukka on natiivikoodissa (moduulin \path{nativerunners.c}
funktiossa
\path{Java_fi_helsinki_cs_tituomin_nativebenchmark_benchmark_C2JBenchmark00026_runInternal}),
täytyy jo tätä fuktiota kutsua JNI:n kautta. Varsinainen mittauskohde
on kuitenkin natiivikoodin kutsuma \path{(*env)->CallVoidMethod}
-JNI-funktio, jota kautta kutsutaan Java-komponentissa olevaa
\path{JavaCounterparts}-luokan tyhjää metodia.

#+NAME: fig:sequence_c_to_c
#+INCLUDE: ../../src/figures/sequence-c-to-c.puml" src plantuml :results file :file /tmp/sequence-c-to-c.png :exports results
#+ATTR_LATEX: :width {0.8\linewidth} :placement [h]
#+CAPTION: Natiivikomponentista kutsutaan natiivikomponenttia
#+LABEL: fig:sequence_c_to_c
#+RESULTS: fig:sequence_c_to_c

Kuvan \ref{fig:sequence_c_to_c} tilanne on jäljelle jäänyt
permutaatio, jossa koko mitattava suoritus tapahtuu
natiivikomponentissa.

# Mainitse BenchmarkParameter?

* Testilaitteisto

Google Nexus S
# https://en.wikipedia.org/wiki/Nexus_S

* Mittaamisen haasteita

Mittauksien käynnistämistä monimutkaistaa hieman se, että eri
mittaustyökalut suorittavat samat kohdeoperaatiot eri tavoilla.

Yksinkertaisempi tapaus on vasteaikojen mittaus
\path{JavaSystemNanoResponseTimeRecorder}-luokalla: lähtösilmukkaa suoritetaan
yhteensä aina täsmälleen ennalta määrätyn kierroslukumäärän verran.
\path{JavaSystemNanoResponseTimeRecorder} ottaa talteen järjestelmän kellon
arvon ennen kierrosten suoritusta ja sen jälkeen.

Kutsuprofiilia luotaessa kaikkia lähtösilmukoita tulee sen sijaan
suorittaa niin kauan, että ~perf record~ -työkalu on saanut
kerättyä riittävän määrän näytteitä -- esimerkiksi 10 sekunnin ajan
jokaista benchmarkia kohden. Näin ollen lähtösilmukoita ajetaan,
kunnes mittaava komponentti \path{LinuxPerfRecordTool} keskeyttää
benchmark-säikeen suorituksen. Tämä monimutkaistaa lähtösilmukoita,
sillä niiden on itse tutkittava, onko mittaus keskeytetty, ja tehtävä
se tarpeeksi harvoin, jotta se ei vaikuta suoritusaikoihin.

* Mittaamisen perusrasitteet

Eri permutaatioiden sekvenssikaavioista (kuvat
\ref{fig:sequence_java_to_c}--\ref{fig:sequence_c_to_c}) voi huomata,
että mitattava ohjelmakoodi vaihtelee sen mukaan, onko ~runInternal~
-metodi ja lähtösilmukka Java- vai natiivikomponentissa. Kun se on
Java-komponentissa, Dalvik ensin tulkitsee silmukkaa ja sitten
JIT-kääntää sen suorittaakseen kääntämäänsä versiota silmukasta. Kun
lähtösilmukka on natiivikomponentissa, C-kääntäjän tuottamaa
konekielistä versiota suoritetaan sellaisenaan.

Koska on mahdotonta kontrolloida, miten erilaisia kaksi eri versiota
lähtösilmukasta konekielitasolla ovat, ei niiden suoritusaikojakaan
periaatteessa voi suoraan vertailla. Niiden erojen mittaamiseksi
molempien versioiden perusrasitetta arvioitiin seuraavalla
menetelmällä. Kummastakin lähtösilmukasta luotiin benchmarksarjat,
jossa suoraan silmukan sisälle lisätään /n/ kappaletta identtistä
ohjelmalohkoa, jotka suorittavat hyödyttömiä mutta tarpeeksi raskaita
ja sivuvaikutuksellisia aritmeettisia operaatioita paikallisilla
muuttujilla. Interpoloimalla saaduista vasteajoista kun /n/:n arvoa
varioidaan lineaarisesti, saadaan arvioitua, mikä mittausmenetelmän
pohjavasteaika on /n/:n arvolla 0 (tyhjä lähtösilmukka). Näin saadaan
tarkempi arvio perusrasitteesta kuin pelkästään ajamalla tyhjää
lähtösilmukkaa -- erityisesti Java-koodin tapauksessa Java- tai
JIT-kääntäjä saattaa myös optimoida pois tyhjän silmukan, jolla ei ole
sivuvaikutuksia.

# TODO two plots below: scale 50%

{{{plot(02)}}}

{{{plot(04)}}}


# TODO viite ylle
# TODO XXXXXXX

* Muistia allokoivat operaatiot

Muistia allokoivia JNI-operaatioita, jotka esimerkiksi luovat olioita,
ei voi suorittaa tuhansia kertoja ilman että sovelluksen muisti
loppuu. Yleensä mittauksissa on pyritty pitämään kierrosmäärä niin
suurena kuin käytännössä on järkevää, jotta satunnaisten
järjestelmässä esiintyvien häiriöiden suuruus verrattuna mitattuihin
kokonaisvasteaikoihin olisi pieni. Allokoivissa operaatioissa silmukan
kierrosmäärä pidetään alhaisena, mutta vastaavasti samoja mittauksia
suoritetaan useampia ajoja ja saadut luvut yhdistetään
tilastollisesti.

# TODO tilastollisesti: miten ?

Javan tapauksessa väliaikaisten olioiden allokointi aiheuttaa
lisäksi roskienkeruuta ennakoimattomina ajankohtina. Mittauksissa
roskienkeruun aiheuttama sinänsä oleellinen rasite suorituskyvylle on
päätetty yksinkertaisuuden vuoksi jättää huomiotta. Roskienkeruuta
ehdotetaan virtuaalikoneelle ~System.gc()~ -kutsulla mittausajojen
ulkopuolella. Androidin lokien perusteella virtuaalikone myös näyttää
käytännössä ajavan roskienkeruun halutulla
ajoituksella. Mittaustuloksien mukaan lisätään ote Androidin
järjestelmälokista, mistä voidaan havaita mahdolliset häiriöitä
aiheuttavat roskienkeruutapahtumat.

Viimeinen ongelma allokoivissa operaatioissa on, että käynnistettäessä
Android-sovellukselle annetaan sallittua maksimikokoa pienempi keko,
jonka kasvattaminen tarpeen mukaan taas saattaa aiheuttaa
suorituskykyhäiriöitä. Ongelmaa on vältetty allokoimalla heti
sovelluksen käynnistyessä suuri taulukko-olio, johon saatu viite
tuhotaan heti roskienkeruun mahdollistameksi.

* JIT-käännös

Dalvik sisältää JIT-kääntäjän \ref{sec-dalvik-intro}, jonka toiminta
tekee Java-koodin käyttäytymisestä vaikeasti ennustettavaa: koska
mittauksessa suoritetaan samaa silmukkaa jatkuvasti, on melko varmaa
että se JIT-käännetään jossain vaiheessa, mutta suorituksen aluksi
silmukan tavukoodia tulkitaan. Ratkaisuyritys ongelmaan on suorittaa
ennen varsinaisia mittauksia lämmittelyajo, jonka kierrosmäärä on
arvioitu riittäväksi JIT-kääntämisen laukaisemiseksi.

Oikean kierrosmäärän arvioimiseksi ja JIT-käännöksen todentamiseksi
tehtiin mittaus, jossa samaa benchmarkia suoritetaan pienehköllä
silmukkakierrosluvulla mutta monessa perättäisessä ajossa, ja
seurataan peräkkäisten vasteaikojen kehittymistä.

\begin{figure}
    \input{figures/warmup-proof}
\end{figure}

# TODO tähän mittaus ja kuva !important
# TODO tähän kuva vasteaika vs. mittausajo.

* Benchmark Generator

/Benchmark Generator/ on Python-kielinen ohjelma, joka tuottaa
/NativeBenchmark/-sovelluksen lähtösilmukat sekä kutsujen kohteena
olevat tynkämetodit. Ohjelma myös tulostaa C-kieliset moduulit sekä
Java-kieliset luokat, joihin kyseiset silmukat ja metodit sijoitetaan.

#+NAME: fig:benchmark_generator_architecture
#+INCLUDE: "../../src/figures/architecture-benchmark-generator.puml" src plantuml :results file :file /tmp/architecture-benchmark_generator.png :exports results
#+CAPTION: Benchmark Generator: komponentit
#+LABEL: fig:benchmark_generator_architecture
#+RESULTS: fig:benchmark_generator_architecture

Kuvan \ref{fig:benchmark_generator_architecture} alaosasta nähdään,
että ~benchmark_generator~-päämoduulia kutsuu automaattisesti
Ant-käännöstyökalu, ja generoidut lähdekooditiedostot tulevat näin
osaksi normaaleja Androidin SDK- ja NDK- käännösprosesseja.

Lähdekoodien generointi perustuu seuraavaan kahteen
suunnitteluratkaisuun.  Ensinnäkin generointikoodi ottaa
lähtökohdakseen ~jni_types~-moduulissa määritellyt tietorakenteet,
jotka sisältävät tarvittavat tiedot kaikista Java-ohjelmoinnin
tyypeistä ja niiden vastinpareista C-kielessä.

Java- ja C-koodia käsitellään merkkijonoina eikä esimerkiksi
rakenteellisina syntaksipuina, mutta monimutkaisia
lähdekoodimerkkijonoja on vältetty upottamasta suoraan Python-kielisen
logiikan keskelle. Lähdekoodin generoinnin pohjina toimivat
~templates~-paketista löytyvät aihiot. Ne muistuttavat
HTML-ohjelmoinnissa käytettyjen template-kielten aihioita. Aihiot
koostuvat staattisena pysyvästä kohdekielisestä merkkijonosta, jonka
sisällä olevat paikkamerkit korvataan muuttujien vaihtuvilla arvoilla.

Seuraavassa esimerkissä näkyy ~jni_types~-moduulin ~dict~-tyyppimääritelmä
~int~-primitiivityypille.

#+INCLUDE: "/home/tituomin/nativebenchmark/script/jni_types.py" src python :lines "52-61"
#+LABEL: src:jni-gen-int
#+NAME: src:jni-gen-int
#+CAPTION: foo bar

Tietueen kentistä ~symbol~ on tyypin sisäinen tunniste
generointikoodissa. Kentät ~java~ sekä ~c~ ovat tyypin nimet
molemmissa kielissä, ja ~java-literal~ sekä ~c-literal~ sisältävät
tyyppiä vastaavan literaalin, jonka voi aina lisätä lähdekoodiin, kun
tarvitaan kyseisen tyyppistä arvoa. Kenttä ~jvm-desc~ on
Java-tavukoodissa ja joissain JNI-kutsuissa käytetty tyyppimääritys.
Kentän ~representative~ arvon perusteella voidaan alustavien
mittausten jälkeen välttää turhien benchmarkien aikaavievä suoritus --
esimerkiksi ~int~- ja ~char~-tyyppien välillä ei huomattu mitään eroa,
joten mittauksissa voidaan käyttää vain ~int~-tyyppisiä benchmarkeja
edustamaan molempia.

# Seuraavassa esimerkissä on vastaava määritelmä ~String~-viitetyypille.

# #+INCLUDE: "/home/tituomin/nativebenchmark/script/jni_types.py" src python :lines "118-128"

# Eroa ~int~-tyypiin on erityisesti siinä, ettei C-ohjelmassa ole suoraa
# literaalia Javan ~String~-arvolle (kenttä ~c-literal~). ~String~ on
# myös merkitty viitetyyppiseksi (kenttä ~is-object~).

Generointiin käytettävät aihiot näyttävät seuraavalta. Esimerkki
on tiedostosta \path{templates/c_nativemethod.py}.

#+INCLUDE: "/home/tituomin/nativebenchmark/script/templates/c_nativemethod.py" src python :lines "7-18"

Template-kielen paikkamerkkeinä tulkittavat osat erotetaan
kirjaimellisesti tulkittavasta osasta erottimilla ~<%~ ja ~%>~,
joille ei ole varattua merkitystä kohdekielissä. Kyseisten merkintöjen
käyttöä aihioissa esimerkiksi kohdekielen merkkijonoliteraalin sisällä
ei tueta.

Aihion voi täydentää valittujen parametrien arvoilla
~templating~-moduulin funktioilla ~put~ ja ~partial~. Funktio ~put~
korvaa aihion kaikki paikkamerkit samannimisten nimettyjen parametrien
arvoilla poistaen puuttuvia argumentteja vastaavat
paikkamerkit. Funktio ~partial~ jättää puuttuvien argumenttien
paikkamerkinnät paikoilleen, mikä helpottaa erikoistuneiden aihioiden
johtamista samasta perusaihiosta. Funktiota ~put~ käytetään kuten
seuraavassa esimerkissä.

#+INCLUDE: "/home/tituomin/nativebenchmark/script/make_custom_benchmarks.py" src python :lines "391-398"
#+BEGIN_SRC python
[...]
#+END_SRC

Molemmat funktiot on helppo toteuttaa, kun tukena on
seuraavat Python-sanakirjaluokasta periytetyt kaksi aliluokkaa.

#+INCLUDE: "/home/tituomin/nativebenchmark/script/templating.py" src python :lines "6-13"

Kun ~put~-kutsun nimetyt argumentit tallennetaan ~PurgeDict~-olioon,
mahdollisesti puuttuvien avainten arvoiksi tulee automaattisesti
tyhjä. Vastaavasti ~partial~-kutsun argumentit tallennettuna
~PartialDict~-olioon toimivat niin, että paikkamerkin puuttuva arvo
korvataan samanlaisella paikkamerkillä.

# TODO: pseudokoodi benchmarkit luovasta silmukasta?

* Mittaustulosten käsittelijä Benchmark Analyzer

/NativeBenchmark/-sovelluksen näkökulmasta suoritettavilla
benchmarkeilla ei ole mitään suhdetta toisiinsa, vaan jokainen
suoritetaan toisistaan riippumatta ja jokaisesta mittauksesta
tallennetaan mahdollisimman täydelliset parametritiedot
tekstitiedostoon.  Vasteaikamittauksissa tiedostoon tallennetaan myös
mittaustulos eli vasteaika, kutsuprofiilin tapauksessa sen sijaan
tiedostopolku ~perf record~-työkalun tulostamaan
näytetiedostoon. Seuraavassa on esimerkki tekstitiedoston sisällöstä.

# TODO: konvertoi alle taulukko mittaustiedostosta:
| Class            | Response time | Units | parameter_type_int_count | parameter_type_char_count | very | long | table with lots | and lots of text |
|------------------+---------------+-------+--------------------------+---------------------------+------+------+-----------------+------------------|
| J2Benchmark00026 |             2 |     3 |                        4 |                         5 |      |      |                 |                  |
| 1                |             2 |     3 |                        4 |                         5 |      |      |                 |                  |
|------------------+---------------+-------+--------------------------+---------------------------+------+------+-----------------+------------------|

Koska kaikki varioitavat parametrit on tallennettu tiedostoon,
/Benchmark Analyzer/ -ohjelman tehtäväksi jää yhdistellä jälkikäteen
saman parametrin vaihtelevat arvot yhdeksi mittaussarjaksi ja piirtää
tulokset kuvaajiksi ~gnuplot~-ohjelmalla sekä tulostaa ne taulukoiksi
tekstitiedostoihin. Analyysiohjelmalla on myös käytössään
~jni_types~-moduulin tyyppimääritykset.

* Tilastolliset menetelmät
   2 sivua\newline 10. 2. 2014

   # TODO: ei ole juurikaan käytetty muuta kuin interpolointia

   Käytetyt tilastolliset menetelmät.
